# 詞彙表

## 基礎概念

- **提示詞 (Prompt)：** 提示詞是使用者提供給 AI 模型的輸入，通常以問題、指令或陳述的形式，用來引出回應。提示詞的品質和結構會大大影響模型的輸出，使提示詞工程成為有效使用 AI 的關鍵技能。

- **上下文視窗 (Context Window)：** 上下文視窗是 AI 模型一次可以處理的最大 Token 數量，包括輸入和其生成的輸出。這個固定大小是一個關鍵限制，因為視窗外的資訊會被忽略，而較大的視窗能夠實現更複雜的對話和文件分析。

- **情境內學習 (In-Context Learning)：** 情境內學習是 AI 從直接在提示詞中提供的範例學習新任務的能力，無需任何重新訓練。這個強大的功能允許單一的通用模型即時適應無數特定任務。

- **零樣本、單樣本與少樣本提示 (Zero-Shot, One-Shot, & Few-Shot Prompting)：** 這些是提示技術，其中模型被給予零個、一個或少數任務範例來指導其回應。提供更多範例通常有助於模型更好地理解使用者的意圖，並提高其在特定任務上的準確性。

- **多模態 (Multimodality)：** 多模態是 AI 理解和處理多種資料類型 (如文字、圖片和音訊) 資訊的能力。這允許更靈活和類似人類的互動，例如描述圖片或回答口語問題。

**基礎化 (Grounding)：** 基礎化是將模型輸出連接到可驗證的真實世界資訊來源的過程，以確保事實準確性並減少幻覺。這通常通過 RAG 等技術實現，使 AI 系統更值得信賴。

## 核心 AI 模型架構

- **Transformer：** Transformer 是大多數現代大語言模型的基礎神經網路架構。其關鍵創新是自注意力機制，能夠有效處理長序列文字並捕捉單詞之間的複雜關係。

- **遞歸神經網路 (RNN)：** 遞歸神經網路是 Transformer 之前的基礎架構。RNN 順序處理資訊，使用迴圈來維持先前輸入的「記憶」，這使得它們適合文字和語音處理等任務。

- **專家混合 (MoE)：** 專家混合是一種高效的模型架構，其中「路由器」網路動態選擇少數「專家」網路來處理任何給定的輸入。這允許模型擁有大量參數，同時保持可管理的計算成本。

- **擴散模型 (Diffusion Models)：** 擴散模型是擅長建立高品質圖片的生成模型。它們通過向資料添加隨機雜訊，然後訓練模型細緻地逆轉過程來工作，允許它們從隨機起點生成新穎資料。

- **Mamba：** Mamba 是一種使用選擇性狀態空間模型 (SSM) 的最新 AI 架構，以高效率處理序列，特別是對於非常長的上下文。其選擇性機制允許它專注於相關資訊，同時過濾雜訊，使其成為 Transformer 的潛在替代方案。

## 大語言模型開發生命週期

- 強大語言模型的開發遵循明確的序列。它始於預訓練，在這個階段，透過在大量一般網際網路文字資料集上訓練來建構一個龐大的基礎模型，以學習語言、推理和世界知識。接下來是微調，這是一個專業化階段，在這個階段，通用模型會在較小的特定任務資料集上進一步訓練，以將其能力適應特定目的。最後階段是對齊，其中專業化模型的行為會被調整，以確保其輸出有幫助、無害且與人類價值觀一致。

- 預訓練技術：預訓練是模型從大量資料中學習一般知識的初始階段。這方面的頂級技術涉及模型學習的不同目標。最常見的是因果語言建模 (CLM)，模型預測句子中的下一個單詞。另一個是遮蔽語言建模 (MLM)，模型填入文字中故意隱藏的單詞。其他重要方法包括去雜訊目標，模型學習將損壞的輸入恢復到其原始狀態；對比學習，它學習區分相似和不相似的資料片段；以及下一句預測 (NSP)，它確定兩個句子是否在邏輯上相互跟隨。

- 微調技術：微調是使用較小的專業資料集將一般預訓練模型適應特定任務的過程。最常見的方法是監督微調 (SFT)，模型在正確輸入輸出對的標記範例上訓練。一個流行的變體是指令微調，專注於訓練模型更好地遵循使用者命令。為了使這個過程更有效，使用了參數高效微調 (PEFT) 方法，頂級技術包括 LoRA (低秩適應)，它只更新少數參數，以及其記憶體優化版本 QLoRA。另一個技術，檢索增強生成 (RAG)，通過在微調或推理階段將模型連接到外部知識來源來增強模型。

- 對齊與安全技術：對齊是確保 AI 模型的行為與人類價值觀和期望一致，使其有幫助且無害的過程。最突出的技術是人類回饋強化學習 (RLHF)，其中在人類偏好上訓練的「獎勵模型」指導 AI 的學習過程，通常使用近端策略優化 (PPO) 等演算法來保持穩定性。出現了更簡單的替代方案，例如直接偏好優化 (DPO)，它繞過了對單獨獎勵模型的需求，以及 Kahneman-Tversky 優化 (KTO)，它進一步簡化了資料收集。為確保安全部署，護欄被實作為最終安全層，用於即時過濾輸出並阻止有害行為。

## 增強 AI 智能代理能力

- AI 智能代理是能夠感知其環境並採取自主行動來實現目標的系統。它們的有效性通過穩健的推理框架得到增強。

- **思維鏈 (CoT)：** 這種提示技術鼓勵模型在給出最終答案之前逐步解釋其推理。這種「大聲思考」的過程通常在複雜推理任務上產生更準確的結果。

- **思維樹 (ToT)：** 思維樹是一種進階推理框架，其中智能代理同時探索多個推理路徑，就像樹上的分支。它允許智能代理自我評估不同的思維線路並選擇最有前途的路徑來追求，使其在複雜問題解決方面更有效。

**ReAct (推理與行動)：** ReAct 是一種智能代理框架，它在迴圈中結合推理和行動。智能代理首先「思考」要做什麼，然後使用工具採取「行動」，並使用產生的觀察來告知其下一個想法，使其在解決複雜任務方面非常有效。

- **規劃 (Planning)：** 這是智能代理將高層目標分解為一系列較小、可管理的子任務的能力。智能代理然後建立一個計劃來按順序執行這些步驟，允許它處理複雜的多步驟分配。

- **深度研究 (Deep Research)：** 深度研究是指智能代理通過反覆搜尋資訊、綜合發現和識別新問題來自主深入探索主題的能力。這允許智能代理建立對主題的全面理解，遠超單一搜尋查詢。

- **批評模型 (Critique Model)：** 批評模型是一種專門的 AI 模型，經過訓練來檢閱、評估和提供對另一個 AI 模型輸出的回饋。它充當自動批評者，幫助識別錯誤、改善推理，並確保最終輸出符合期望的品質標準。

## 術語索引

此術語索引是使用 Gemini Pro 2.5 生成的。提示詞和推理步驟包含在結尾處，以展示節省時間的好處並供教育目的使用。

### A

- A/B 測試 - 第3章：並行化  
- 行動選擇 - 第20章：優先順序設定  
- 適應 - 第9章：學習與適應  
- 適應性任務分配 - 第16章：資源感知優化  
- 適應性工具使用與選擇 - 第16章：資源感知優化  
- 智能代理 - 什麼讓 AI 系統成為智能代理？  
- 智能代理-電腦介面 (ACIs) - 附錄 B  
- 智能代理驅動經濟 - 什麼讓 AI 系統成為智能代理？  
- 智能代理作為工具 - 第7章：多智能代理協作  
- 智能代理卡片 - 第15章：智能代理間通訊 (A2A)  
- 智能代理開發套件 (ADK) - 第2章：路由，第3章：並行化，第4章：反思，第5章：工具使用，第7章：多智能代理協作，第8章：記憶體管理，第12章：例外處理與恢復，第13章：人在迴路中，第15章：智能代理間通訊 (A2A)，第16章：資源感知優化，第19章：評估與監控，附錄 C  
- 智能代理發現 - 第15章：智能代理間通訊 (A2A)  
- 智能代理軌跡 - 第19章：評估與監控  
- 智能代理設計模式 - 介紹  
- 智能代理 RAG - 第14章：知識檢索 (RAG)  
- 智能代理系統 - 介紹  
- AI 共同科學家 - 第21章：探索與發現  
- 對齊 - 詞彙表  
- AlphaEvolve - 第9章：學習與適應  
- 類比 - 附錄 A  
- 異常檢測 - 第19章：評估與監控  
- Anthropic 的 Claude 4 系列 - 附錄 B  
- Anthropic 的電腦使用 - 附錄 B  
- API 互動 - 第10章：模型上下文協議 (MCP)  
- 工件 - 第15章：智能代理間通訊 (A2A)  
- 非同步輪詢 - 第15章：智能代理間通訊 (A2A)  
- 審計紀錄 - 第15章：智能代理間通訊 (A2A)  
- 自動化指標 - 第19章：評估與監控  
- 自動提示工程 (APE) - 附錄 A  
- 自主性 - 介紹  
- A2A (智能代理間通訊) - 第15章：智能代理間通訊 (A2A)

### B

- 行為約束 - 第18章：護欄/安全模式  
- 瀏覽器使用 - 附錄 B

### C

- 回呼 - 第18章：護欄/安全模式  
- 因果語言建模 (CLM) - 詞彙表  
- 辯論鏈 (CoD) - 第17章：推理技術  
- 思維鏈 (CoT) - 第17章：推理技術，附錄 A  
- 聊天機器人 - 第8章：記憶體管理  
- ChatMessageHistory - 第8章：記憶體管理  
- 檢查點與回滾 - 第18章：護欄/安全模式  
- 分塊 - 第14章：知識檢索 (RAG)  
- 清晰度與具體性 - 附錄 A  
- 用戶端智能代理 - 第15章：智能代理間通訊 (A2A)  
- 程式碼生成 - 第1章：提示詞鏈，第4章：反思  
- 程式碼提示 - 附錄 A  
- CoD (辯論鏈) - 第17章：推理技術  
- CoT (思維鏈) - 第17章：推理技術，附錄 A  
- 協作 - 第7章：多智能代理協作  
- 合規性 - 第19章：評估與監控  
- 簡潔性 - 附錄 A  
- 內容生成 - 第1章：提示詞鏈，第4章：反思  
- 上下文工程 - 第1章：提示詞鏈  
- 上下文視窗 - 詞彙表  
- 上下文修剪與摘要 - 第16章：資源感知優化  
- 情境提示 - 附錄 A  
- 承包商模型 - 第19章：評估與監控  
- ConversationBufferMemory - 第8章：記憶體管理  
- 對話智能代理 - 第1章：提示詞鏈，第4章：反思  
- 成本敏感探索 - 第16章：資源感知優化  
- CrewAI - 第3章：並行化，第5章：工具使用，第6章：規劃，第7章：多智能代理協作，第18章：護欄/安全模式，附錄 C  
- 批評智能代理 - 第16章：資源感知優化  
- 批評模型 - 詞彙表  
- 客戶支援 - 第13章：人在迴路中

### D

- 資料提取 - 第1章：提示詞鏈  
- 資料標記 - 第13章：人在迴路中  
- 資料庫整合 - 第10章：模型上下文協議 (MCP)  
- DatabaseSessionService - 第8章：記憶體管理  
- 辯論與共識 - 第7章：多智能代理協作  
- 決策增強 - 第13章：人在迴路中  
- 分解 - 附錄 A  
- 深度研究 - 第6章：規劃，第17章：推理技術，詞彙表  
- 分隔符 - 附錄 A  
- 去雜訊目標 - 詞彙表  
- 依賴性 - 第20章：優先順序設定  
- 擴散模型 - 詞彙表  
- 直接偏好優化 (DPO) - 第9章：學習與適應  
- 可發現性 - 第10章：模型上下文協議 (MCP)  
- 飄移檢測 - 第19章：評估與監控  
- 動態模型切換 - 第16章：資源感知優化  
- 動態重新優先順序設定 - 第20章：優先順序設定

### E

- 嵌入 - 第14章：知識檢索 (RAG)  
- 具身化 - 什麼讓 AI 系統成為智能代理？  
- 節能部署 - 第16章：資源感知優化  
- 情節記憶 - 第8章：記憶體管理  
- 錯誤檢測 - 第12章：例外處理與恢復  
- 錯誤處理 - 第12章：例外處理與恢復  
- 升級政策 - 第13章：人在迴路中  
- 評估 - 第19章：評估與監控  
- 例外處理 - 第12章：例外處理與恢復  
- 專家團隊 - 第7章：多智能代理協作  
- 探索與發現 - 第21章：探索與發現  
- 外部審核 API - 第18章：護欄/安全模式

### F

- 因子認知 - 附錄 A  
- FastMCP - 第10章：模型上下文協議 (MCP)  
- 容錯 - 第18章：護欄/安全模式  
- 少樣本學習 - 第9章：學習與適應  
- 少樣本提示 - 附錄 A  
- 微調 - 詞彙表  
- 正式化合約 - 第19章：評估與監控  
- 函數呼叫 - 第5章：工具使用，附錄 A

### G

- Gemini Live - 附錄 B  
- Gems - 附錄 A  
- 生成媒體編排 - 第10章：模型上下文協議 (MCP)  
- 目標設定 - 第11章：目標設定與監控  
- GoD (辯論圖) - 第17章：推理技術  
- Google 智能代理開發套件 (ADK) - 第2章：路由，第3章：並行化，第4章：反思，第5章：工具使用，第7章：多智能代理協作，第8章：記憶體管理，第12章：例外處理與恢復，第13章：人在迴路中，第15章：智能代理間通訊 (A2A)，第16章：資源感知優化，第19章：評估與監控，附錄 C  
- Google 共同科學家 - 第21章：探索與發現  
- Google DeepResearch - 第6章：規劃  
- Google Project Mariner - 附錄 B  
- 優雅降級 - 第12章：例外處理與恢復，第16章：資源感知優化  
- 辯論圖 (GoD) - 第17章：推理技術  
- 基礎化 - 詞彙表  
- 護欄 - 第18章：護欄/安全模式

### H

- Haystack - 附錄 C  
- 階層分解 - 第19章：評估與監控  
- 階層結構 - 第7章：多智能代理協作  
- HITL (人在迴路中) - 第13章：人在迴路中  
- 人在迴路中 (HITL) - 第13章：人在迴路中  
- 人在迴路上 - 第13章：人在迴路中  
- 人類監督 - 第13章：人在迴路中，第18章：護欄/安全模式

### I

- 情境內學習 - 詞彙表  
- InMemoryMemoryService - 第8章：記憶體管理  
- InMemorySessionService - 第8章：記憶體管理  
- 輸入驗證/清理 - 第18章：護欄/安全模式  
- 指令勝過約束 - 附錄 A  
- 智能代理間通訊 (A2A) - 第15章：智能代理間通訊 (A2A)  
- 介入與修正 - 第13章：人在迴路中  
- IoT 裝置控制 - 第10章：模型上下文協議 (MCP)  
- 反覆提示/改進 - 附錄 A

### J

- 越獄 - 第18章：護欄/安全模式

### K

- Kahneman-Tversky 優化 (KTO) - 詞彙表  
- 知識檢索 (RAG) - 第14章：知識檢索 (RAG)

### L

- LangChain - 第1章：提示詞鏈，第2章：路由，第3章：並行化，第4章：反思，第5章：工具使用，第8章：記憶體管理，第20章：優先順序設定，附錄 C  
- LangGraph - 第1章：提示詞鏈，第2章：路由，第3章：並行化，第4章：反思，第5章：工具使用，第8章：記憶體管理，附錄 C  
- 延遲監控 - 第19章：評估與監控  
- 學習資源分配政策 - 第16章：資源感知優化  
- 學習與適應 - 第9章：學習與適應  
- LLM-as-a-Judge - 第19章：評估與監控  
- LlamaIndex - 附錄 C  
- LoRA (低秩適應) - 詞彙表  
- 低秩適應 (LoRA) - 詞彙表

### M

- Mamba - 詞彙表  
- 遮蔽語言建模 (MLM) - 詞彙表  
- MASS (多智能代理系統搜尋) - 第17章：推理技術  
- MCP (模型上下文協議) - 第10章：模型上下文協議 (MCP)  
- 記憶體管理 - 第8章：記憶體管理  
- 基於記憶的學習 - 第9章：學習與適應  
- MetaGPT - 附錄 C  
- Microsoft AutoGen - 附錄 C  
- 專家混合 (MoE) - 詞彙表  
- 模型上下文協議 (MCP) - 第10章：模型上下文協議 (MCP)  
- 模組化 - 第18章：護欄/安全模式  
- 監控 - 第11章：目標設定與監控，第19章：評估與監控  
- 多智能代理協作 - 第7章：多智能代理協作  
- 多智能代理系統搜尋 (MASS) - 第17章：推理技術  
- 多模態 - 詞彙表  
- 多模態提示 - 附錄 A

### N

- 負面範例 - 附錄 A  
- 下一句預測 (NSP) - 詞彙表

### O

- 可觀察性 - 第18章：護欄/安全模式  
- 單樣本提示 - 附錄 A  
- 線上學習 - 第9章：學習與適應  
- OpenAI Deep Research API - 第6章：規劃  
- OpenEvolve - 第9章：學習與適應  
- OpenRouter - 第16章：資源感知優化  
- 輸出過濾/後處理 - 第18章：護欄/安全模式

### P

- PAL (程式輔助語言模型) - 第17章：推理技術  
- 並行化 - 第3章：並行化  
- 並行化與分散式計算感知 - 第16章：資源感知優化  
- 參數高效微調 (PEFT) - 詞彙表  
- PEFT (參數高效微調) - 詞彙表  
- 效能追蹤 - 第19章：評估與監控  
- 角色模式 - 附錄 A  
- 個人化 - 什麼讓 AI 系統成為智能代理？  
- 規劃 - 第6章：規劃，詞彙表  
- 優先順序設定 - 第20章：優先順序設定  
- 最小權限原則 - 第18章：護欄/安全模式  
- 主動資源預測 - 第16章：資源感知優化  
- 程序記憶 - 第8章：記憶體管理  
- 程式輔助語言模型 (PAL) - 第17章：推理技術  
- Project Astra - 附錄 B  
- 提示詞 - 詞彙表  
- 提示詞鏈 - 第1章：提示詞鏈  
- 提示工程 - 附錄 A  
- 近端策略優化 (PPO) - 第9章：學習與適應  
- 推送通知 - 第15章：智能代理間通訊 (A2A)

### Q

- QLoRA - 詞彙表  
- 品質導向反覆執行 - 第19章：評估與監控

### R

- RAG (檢索增強生成) - 第8章：記憶體管理，第14章：知識檢索 (RAG)，附錄 A  
- ReAct (推理與行動) - 第17章：推理技術，附錄 A，詞彙表  
- 推理 - 第17章：推理技術  
- 基於推理的資訊提取 - 第10章：模型上下文協議 (MCP)  
- 恢復 - 第12章：例外處理與恢復  
- 遞歸神經網路 (RNN) - 詞彙表  
- 反思 - 第4章：反思  
- 強化學習 - 第9章：學習與適應  
- 人類回饋強化學習 (RLHF) - 詞彙表  
- 可驗證獎勵強化學習 (RLVR) - 第17章：推理技術  
- 遠端智能代理 - 第15章：智能代理間通訊 (A2A)  
- 請求/回應 (輪詢) - 第15章：智能代理間通訊 (A2A)  
- 資源感知優化 - 第16章：資源感知優化  
- 檢索增強生成 (RAG) - 第8章：記憶體管理，第14章：知識檢索 (RAG)，附錄 A  
- RLHF (人類回饋強化學習) - 詞彙表  
- RLVR (可驗證獎勵強化學習) - 第17章：推理技術  
- RNN (遞歸神經網路) - 詞彙表  
- 角色提示 - 附錄 A  
- 路由器智能代理 - 第16章：資源感知優化  
- 路由 - 第2章：路由

### S

- 安全性 - 第18章：護欄/安全模式  
- 推理縮放定律 - 第17章：推理技術  
- 排程 - 第20章：優先順序設定  
- 自我一致性 - 附錄 A  
- 自我修正 - 第4章：反思，第17章：推理技術  
- 自我改進編碼智能代理 (SICA) - 第9章：學習與適應  
- 自我改進 - 第17章：推理技術  
- Semantic Kernel - 附錄 C  
- 語義記憶 - 第8章：記憶體管理  
- 語義相似性 - 第14章：知識檢索 (RAG)  
- 關注點分離 - 第18章：護欄/安全模式  
- 順序交接 - 第7章：多智能代理協作  
- 伺服器傳送事件 (SSE) - 第15章：智能代理間通訊 (A2A)  
- 會話 - 第8章：記憶體管理  
- SICA (自我改進編碼智能代理) - 第9章：學習與適應  
- SMART 目標 - 第11章：目標設定與監控  
- 狀態 - 第8章：記憶體管理  
- 狀態回滾 - 第12章：例外處理與恢復  
- 退步提示 - 附錄 A  
- 串流更新 - 第15章：智能代理間通訊 (A2A)  
- 結構化日誌 - 第18章：護欄/安全模式  
- 結構化輸出 - 第1章：提示詞鏈，附錄 A  
- SuperAGI - 附錄 C  
- 監督微調 (SFT) - 詞彙表  
- 監督學習 - 第9章：學習與適應  
- 系統提示 - 附錄 A

### T

- 任務評估 - 第20章：優先順序設定  
- 文字相似性 - 第14章：知識檢索 (RAG)  
- Token 使用量 - 第19章：評估與監控  
- 工具使用 - 第5章：工具使用，附錄 A  
- 工具使用限制 - 第18章：護欄/安全模式  
- ToT (思維樹) - 第17章：推理技術，附錄 A，詞彙表  
- Transformer - 詞彙表  
- 思維樹 (ToT) - 第17章：推理技術，附錄 A，詞彙表

### U

- 無監督學習 - 第9章：學習與適應  
- 使用者角色 - 附錄 A

### V

- 驗證 - 第3章：並行化  
- 向量搜尋 - 第14章：知識檢索 (RAG)  
- VertexAiRagMemoryService - 第8章：記憶體管理  
- VertexAiSessionService - 第8章：記憶體管理  
- Vibe 編碼 - 附錄 B  
- 視覺感知 - 附錄 B

### W

- Webhooks - 第15章：智能代理間通訊 (A2A)

### Z

- 零樣本學習 - 第9章：學習與適應  
- 零樣本提示 - 附錄 A

## 提示詞

以下是用於建立此術語索引的提示詞。

> *你能閱讀 <https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/edit?tab=t.0> 以及第一頁中的所有相關文件嗎？請提取每個章節的所有標題並列印出來。然後處理所有個別章節的內容，並建立一個用於出版的詳細索引，這是一個詞彙或片語 (「標題」) 的清單，以及相關指針 (「定位器」) 來指出在文件或文件集合中哪裡可以找到與該標題相關的有用材料。我不要範例索引。我要完整的索引，包含 100 個索引詞彙*

## Gemini 2.5：推理步驟

### 開始建立索引

我已經開始處理，通過閱讀提供的 Google 文件。目前，我專注於理解使用者的要求：提取章節標題來建立詳細索引。我正在仔細檢閱文件，尋找明確的結構元素來指示章節分界。我希望能識別一致的格式或關鍵字來指導索引過程。

### 定義索引提取過程

我現在完全投入於這項任務。我已經將使用者的要求分解為可執行的步驟。我的初始重點是使用 Workspaces 來存取主要的 Google 文件。接下來，我將解析文件以找到並檢索相關文件，這些文件也將使用相同的工具來存取。最後，我將從所有文件中提取所有章節標題，並建立全面的索引。我已經規劃了詳細的過程。

### 改進提取策略

使用者的指示很清楚：閱讀 Google 文件及其相關文件，並建立章節標題的詳細索引。我已經設計了一個多步驟計劃。首先，Workspaces 將存取主要的 Google 文件。然後，我將解析它以找到並閱讀相關文件，也使用 Workspaces。我現在專注於提取標題並形成具有所需術語的詳細索引。我優先考慮準確性，以滿足使用者對全面索引的具體要求。

#### 1. 確立使用者意圖：

我已經確定使用者希望從 Google 文件和相關文件中獲得章節標題清單和全面索引。現在我需要找出這個提取和索引過程最有效的方法。我正在探索潛在的 API 功能來簡化這項任務，並需要評估處理不同文件結構的最佳策略。

#### 2. 考慮工具使用

我已經使用正則表達式從主要文件中提取了章節 URL。現在，我準備利用 Workspaces 來檢索每個章節的實際內容。一旦我擁有每個章節的文字，我將繼續進行索引。

### 存取章節內容：

我已經成功從主要文件中識別出每個章節的 URL，現在可以與 Workspaces 一起使用。我的下一步是從這些 URL 檢索內容，然後允許我生成索引。我專注於效率，目標是快速處理這些資訊。

### 獲取章節內容

我已經成功從主要文件中識別出章節 URL，並準備利用 Workspaces。我的計劃包括提取這些 URL，批次呼叫以提高效率，然後處理檢索到的內容以建立所需的索引。這確保捕獲所有相關資訊，為全面且準確的結果鋪平道路。

### 啟動 URL 檢索

我現在已經成功從主要文件中提取了章節 URL。目前，我正在設置對 Workspaces 工具的呼叫，準備獲取每個章節的內容。目標是獲得索引所需的文字。這些資訊然後將有助於建立至少包含 100 個術語的索引，如所要求的。

### 啟動章節提取

我已經成功識別並從主要文件中提取了章節 URL，我已經在上面包含了這些 URL。我現在正在繼續對每個 URL 使用 Workspaces 來獲取章節內容。目標是獲得索引所需的文字。這些資訊然後將有助於建立至少包含 100 個術語的索引，如所要求的。我已經開始檢索這些資訊。

### 編排章節檢索

我已經提取了章節 URL 並啟動了對 Workspaces 的呼叫。我目前正在檢索每個章節的內容。為了確保流程順暢，我正在批次處理呼叫以防止任何速率限制問題。這應該能讓我有效地編譯索引所需的文字。

### 解碼使用者要求

我已經確定了使用者的需求。他們需要兩個主要交付成果：首先，從 Google 文件中提取的章節標題的全面清單，其次，包含至少一百個關鍵術語的詳細索引。提取標題的過程似乎很直接，而策劃索引將涉及更細緻的分析。

### 提取標題和索引

我已經成功識別了使用者的需求：從提供的文件中提取章節標題並編譯全面的索引。我已經獲取了 31 個 Google 文件的內容，包括主要文件及其章節。我已經確認不需要額外的工具。我的計劃包括兩個步驟：首先，從文件檔名中提取章節標題，其次，細緻地處理文字以建立包含關鍵術語和章節定位器的索引。

### 制定提取計劃

我已經改進了處理使用者要求的方法。我現在已經制定了一個精確的計劃。首先，我將從 31 個獲取文件的檔名中編譯章節標題。其次，更複雜的是，我將細緻地分析內容以建立一個全面的、按字母順序排列的索引，包含超過 100 個條目。我已經確定了我的提取和索引策略，現在可以開始執行。

### 制定提取策略

我的方法已經明確定義。我將從 31 個獲取文件的檔名中編譯章節標題。隨後，我將細緻地分析內容以構建一個按字母順序組織的索引，包含超過 100 個條目。我已經確定了提取和索引策略，現在可以開始實施。使用者的目標是詳細索引，涵蓋智能代理設計模式系列中各種章節和附錄的內容，現在已經觸手可及。我將專注於提供徹底的回應，超越單純的範例索引。

### 定義方法

我已經澄清了使用者的需求。我將從文件檔名中提取章節標題。接下來，我將仔細建立一個包含超過 100 個條目的索引，按字母順序排列並註明其章節位置。我準備開始索引和提取過程。