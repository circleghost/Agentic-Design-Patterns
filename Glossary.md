# 詞彙表

## 基礎概念

**提示詞 (Prompt)：** 提示詞是使用者提供給 AI 模型的輸入，通常以問題、指令或陳述的形式，用來引出回應。提示詞的品質和結構會大大影響模型的輸出，使提示詞工程成為有效使用 AI 的關鍵技能。

**上下文視窗 (Context Window)：** 上下文視窗是 AI 模型一次可以處理的最大 Token 數量，包括輸入和其生成的輸出。這個固定大小是一個關鍵限制，因為視窗外的資訊會被忽略，而較大的視窗能夠實現更複雜的對話和文件分析。

**情境內學習 (In-Context Learning)：** 情境內學習是 AI 從直接在提示詞中提供的範例學習新任務的能力，無需任何重新訓練。這個強大的功能允許單一的通用模型即時適應無數特定任務。

**零樣本、單樣本與少樣本提示 (Zero-Shot, One-Shot, & Few-Shot Prompting)：** 這些是提示技術，其中模型被給予零個、一個或少數任務範例來指導其回應。提供更多範例通常有助於模型更好地理解使用者的意圖，並提高其在特定任務上的準確性。

**多模態 (Multimodality)：** 多模態是 AI 理解和處理多種資料類型 (如文字、圖片和音訊) 資訊的能力。這允許更靈活和類似人類的互動，例如描述圖片或回答口語問題。

**基礎化 (Grounding)：** 基礎化是將模型輸出連接到可驗證的真實世界資訊來源的過程，以確保事實準確性並減少幻覺。這通常通過 RAG 等技術實現，使 AI 系統更值得信賴。

## 核心 AI 模型架構

**Transformer：** Transformer 是大多數現代大語言模型的基礎神經網路架構。其關鍵創新是自注意力機制，能夠有效處理長序列文字並捕捉單詞之間的複雜關係。

**遞歸神經網路 (RNN)：** 遞歸神經網路是 Transformer 之前的基礎架構。RNN 順序處理資訊，使用迴圈來維持先前輸入的「記憶」，這使得它們適合文字和語音處理等任務。

**專家混合 (MoE)：** 專家混合是一種高效的模型架構，其中「路由器」網路動態選擇少數「專家」網路來處理任何給定的輸入。這允許模型擁有大量參數，同時保持可管理的計算成本。

**擴散模型 (Diffusion Models)：** 擴散模型是擅長建立高品質圖片的生成模型。它們通過向資料添加隨機雜訊，然後訓練模型細緻地逆轉過程來工作，允許它們從隨機起點生成新穎資料。

**Mamba：** Mamba 是一種使用選擇性狀態空間模型 (SSM) 的最新 AI 架構，以高效率處理序列，特別是對於非常長的上下文。其選擇性機制允許它專注於相關資訊，同時過濾雜訊，使其成為 Transformer 的潛在替代方案。

## 大語言模型開發生命週期

強大語言模型的開發遵循明確的序列。它始於預訓練，在這個階段，透過在大量一般網際網路文字資料集上訓練來建構一個龐大的基礎模型，以學習語言、推理和世界知識。接下來是微調，這是一個專業化階段，在這個階段，通用模型會在較小的特定任務資料集上進一步訓練，以將其能力適應特定目的。最後階段是對齊，其中專業化模型的行為會被調整，以確保其輸出有幫助、無害且與人類價值觀一致。

**預訓練技術：** 預訓練是模型從大量資料中學習一般知識的初始階段。這方面的頂級技術涉及模型學習的不同目標。最常見的是因果語言建模 (CLM)，模型預測句子中的下一個單詞。另一個是遮蔽語言建模 (MLM)，模型填入文字中故意隱藏的單詞。其他重要方法包括去雜訊目標，模型學習將損壞的輸入恢復到其原始狀態；對比學習，它學習區分相似和不相似的資料片段；以及下一句預測 (NSP)，它確定兩個句子是否在邏輯上相互跟隨。

**微調技術：** 微調是使用較小的專業資料集將一般預訓練模型適應特定任務的過程。最常見的方法是監督微調 (SFT)，模型在正確輸入輸出對的標記範例上訓練。一個流行的變體是指令微調，專注於訓練模型更好地遵循使用者命令。為了使這個過程更有效，使用了參數高效微調 (PEFT) 方法，頂級技術包括 LoRA (低秩適應)，它只更新少數參數，以及其記憶體優化版本 QLoRA。另一個技術，檢索增強生成 (RAG)，通過在微調或推理階段將模型連接到外部知識來源來增強模型。

**對齊與安全技術：** 對齊是確保 AI 模型的行為與人類價值觀和期望一致，使其有幫助且無害的過程。最突出的技術是人類回饋強化學習 (RLHF)，其中在人類偏好上訓練的「獎勵模型」指導 AI 的學習過程，通常使用近端策略優化 (PPO) 等演算法來保持穩定性。出現了更簡單的替代方案，例如直接偏好優化 (DPO)，它繞過了對單獨獎勵模型的需求，以及 Kahneman-Tversky 優化 (KTO)，它進一步簡化了資料收集。為確保安全部署，護欄被實作為最終安全層，用於即時過濾輸出並阻止有害行為。

## 增強 AI 智能代理能力

AI 智能代理是能夠感知其環境並採取自主行動來實現目標的系統。它們的有效性通過穩健的推理框架得到增強。

**思維鏈 (CoT)：** 這種提示技術鼓勵模型在給出最終答案之前逐步解釋其推理。這種「大聲思考」的過程通常在複雜推理任務上產生更準確的結果。

**思維樹 (ToT)：** 思維樹是一種進階推理框架，其中智能代理同時探索多個推理路徑，就像樹上的分支。它允許智能代理自我評估不同的思維線路並選擇最有前途的路徑來追求，使其在複雜問題解決方面更有效。

**ReAct (推理與行動)：** ReAct 是一種智能代理框架，它在迴圈中結合推理和行動。智能代理首先「思考」要做什麼，然後使用工具採取「行動」，並使用產生的觀察來告知其下一個想法，使其在解決複雜任務方面非常有效。

**規劃 (Planning)：** 這是智能代理將高層目標分解為一系列較小、可管理的子任務的能力。智能代理然後建立一個計劃來按順序執行這些步驟，允許它處理複雜的多步驟分配。

**深度研究 (Deep Research)：** 深度研究是指智能代理通過反覆搜尋資訊、綜合發現和識別新問題來自主深入探索主題的能力。這允許智能代理建立對主題的全面理解，遠超單一搜尋查詢。

**批評模型 (Critique Model)：** 批評模型是一種專門的 AI 模型，經過訓練來檢閱、評估和提供對另一個 AI 模型輸出的回饋。它充當自動批評者，幫助識別錯誤、改善推理，並確保最終輸出符合期望的品質標準。